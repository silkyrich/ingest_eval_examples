[default]
lastChanceIndex=detritus

# Everyone needs a last chance index for recieving all the detritus
[detritus]
homePath = $SPLUNK_DB/detritus/db
coldPath = $SPLUNK_DB/detritus/colddb
thawedPath = $SPLUNK_DB/detritus/thaweddb
maxDataSize=1
journalCompression = zstd
tsidxWritingLevel=4
disabled = 0

# We create two indexes to recieve all the examples for this demo app
[ingest_eval_examples_1]
homePath = $SPLUNK_DB/ingest_eval_examples_1/db
coldPath = $SPLUNK_DB/ingest_eval_examples_1/colddb
thawedPath = $SPLUNK_DB/ingest_eval_examples_1/thaweddb
maxDataSize=1
journalCompression = zstd
tsidxWritingLevel=4
disabled = 0
maxDataSize=1

[ingest_eval_examples_2]
homePath = $SPLUNK_DB/ingest_eval_examples_2/db
coldPath = $SPLUNK_DB/ingest_eval_examples_2/colddb
thawedPath = $SPLUNK_DB/ingest_eval_examples_2/thaweddb
maxDataSize=1
journalCompression = zstd
tsidxWritingLevel=4
disabled = 0
maxDataSize=1

[shard_data_with_splitbyindexkeys]
homePath = $SPLUNK_DB/shard_data_with_splitbyindexkeys/db
coldPath = $SPLUNK_DB/shard_data_with_splitbyindexkeys/colddb
thawedPath = $SPLUNK_DB/shard_data_with_splitbyindexkeys/thaweddb
# we set the size the buckets to be small so they roll more frequently
maxDataSize=1
journalCompression = zstd
tsidxWritingLevel=4
disabled = 0
# the more hots buckets the better the sharding
maxHotBuckets = 20
# we will shard around source and sourcetype
splitByIndexKeys=source,sourcetype